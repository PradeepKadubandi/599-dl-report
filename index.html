<!doctype html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <script src="https://distill.pub/template.v2.js"></script>
  <style><%= require("raw-loader!../static/style.css") %></style>
</head>

<body>

<d-front-matter>
  <script type="text/json">{
  "title": "Learning a Sentence Embedding by Actuation",
  "description": "CSCI 599 Course Project Final Report",
  "password": "svgs",
  "authors": [
    {
      "author": "Team DeepJohn",
      "authorURL": "https://github.com/zhanpenghe/embed2learn/",
      "affiliation": "University of Southern California",
      "affiliationURL": "https://www.cs.usc.edu/"
    }
  ],
  "katex": {
    "delimiters": [
      {
        "left": "$",
        "right": "$",
        "display": false
      },
      {
        "left": "$$",
        "right": "$$",
        "display": true
      }
    ]
  }
  }</script>
</d-front-matter>

<d-title></d-title>

<d-article>

  <h2>
    Goal
  </h2>
  <p>
    In recent years there has been great progress in algorithms in the field of deep reinforcement learning (DRL).
    These algorithms have been applied to learning complex and diverse skills from raw observations.
    Among these successes, learning representations of tasks in the form of latent space is demonstrated 
    to be useful for learning composable skills <d-cite key="hausman2018learning"></d-cite>.
    While skills can be defined discretely with labels and used for planning, in real life,
    humans tend to use natural language to describe a task.
    For example, people can ask "take the cup from home, get on the bus to the office, and give it to me."
    Such natural language instructions provide an expressive way to describe skill primitives 
    and allow the human to be in the loop to assist an agent.
  </p>

  <h2>
    Motivation
  </h2>
  <p>
    We propose a novel method that learns an embedding function that 
    embeds natural language sentences and their composability properties 
    (eg. concatenation) to a continuous latent space.
    Jointly, our approach also learns a policy that conditions on a latent 
    variable and state information with reinforcement learning and 
    variational inference. 
    We will explore the property of our latent space and utilize it 
    as a planning tool for complicated tasks.  
  </p>

  <h2>Related Work</h2>
  <p>
      <b>Language-Guided Agent</b> There has been extensive studies done in the
      language-guided agent domain 
      <d-cite key="macmahon2006walk"></d-cite>, <d-cite key="branavan2009reinforcement"></d-cite>, 
      <d-cite key="misra2017mapping"></d-cite>, <d-cite key="latent_language_2018"></d-cite>, 
      <d-cite key="coreyes2018guiding"></d-cite>.
      Most of these works either learn a policy directly from state 
      and instruction representation or learn an intermediate representation 
      of goal and utilize it for planning.
      In <d-cite key="oh2017zeroshot"></d-cite>, task embedding is used and 
      conditioned on a policy for instruction following, but the instructions 
      used in this work was defined by categorical task parameters rather 
      than natural language. Our work not only explores using natural language 
      as task descriptions but explicitly impose property for planning on 
      our sentence embedding space.
  </p>

  <p><b>Task Embedding</b> Task embedding has been explored by 
    <d-cite key="hausman2018learning"></d-cite>, which learns a mapping from 
    task ID to a continuous space. However, sampling from this embedding 
    function is hard because it takes task ID's, which need to be defined 
    before the pre-training process, as input. 
    Our work utilizes the flexibility of natural languages. This allows us 
    to further utilize our latent space for learning from demonstration 
    and generation trajectory descriptions.
  </p>

  <p>
    <b>Sentence Embedding</b> Sentence embeddings is studied extensively 
    by many researchers. For example, <d-cite key="conneauInferSent"></d-cite> 
    learns a semantic representation by natural language inference. 
    Our work focuses on learning representations to aid the agent to 
    make decisions. Exploiting the advantages of interacting with the 
    environment, our methods should learn a minimal representation of 
    natural language commands and generalize among similar sentences.
  </p>

  <h2>Problem Formulation</h2>
  <p>
      In our multi-task RL setting, we pre-define a set of low-level skills 
      with their descriptions $T = \{ st_1, ..., st_N \} \subset ST$, 
      and accompanying, per-skill reward functions $r_{st \in T}(s, a)$. 
      We would like to learn a controller that takes both state information 
      and natural language commands into account. We also want to learn 
      an embedding function from which we can sample efficiently.
  </p>

  <h2>Models and Approaches</h2>
  <p>
      Our method, as illustrated in Figure 1, is motivated by 
      <d-cite key="hausman2018learning"></d-cite>. The model we design consists 
      of three components: the task embedding network $p_{\phi}: ST \to Z$, 
      the task embedding conditioned policy $\pi_{\theta}: S \times Z \to A$, 
      and the inference network $q_\psi: (S \times A)^H \to Z$.
  </p>

  <figure>
      <div class="l-body">
          <%= require("../static/images/method_improved.svg") %>
        </div>
        <figcaption>
      <span class="figure-number">Figure 1</span>
    </figcaption>
  </figure>

</d-article>



<d-appendix>
  <h3>Acknowledgments</h3>
  <p>
    We are deeply grateful to Joseph J. Lim, Karl Pertsch.
  </p>

  <p>
    Many of our diagrams are based on...
  </p>

  <h3>Author Contributions</h3>
  <p>
    <b>Research:</b> Alex developed ...
  </p>

  <p>
    <b>Writing & Diagrams:</b> The text was initially drafted by...
  </p>


  <d-footnote-list></d-footnote-list>
  <d-citation-list></d-citation-list>
</d-appendix>

<!-- bibliography will be inlined during Distill pipeline's pre-rendering -->
<d-bibliography src="bibliography.bib"></d-bibliography>

</body>
